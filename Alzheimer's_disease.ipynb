{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPUqjiW+8D2GLCHWMBgura+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayank-shriv/Alzheimer-s-Disease_detection/blob/main/Alzheimer's_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üì¶ STEP 1: IMPORT LIBRARIES\n",
        "# ---------------------------------------------\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet101, EfficientNetB7, DenseNet201\n",
        "from keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
        "from keras.applications.densenet import preprocess_input as densenet_preprocess\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üìÇ STEP 2: EXTRACT DATASETS\n",
        "# ---------------------------------------------\n",
        "import zipfile\n",
        "\n",
        "# Define paths for the zip files\n",
        "train_zip_path = \"/content/train.zip\"\n",
        "test_zip_path = \"/content/test.zip\"\n",
        "\n",
        "# Extract the train zip file\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/train\")\n",
        "\n",
        "# Extract the test zip file\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/test\")\n",
        "\n",
        "# Define paths for the extracted directories\n",
        "train_path = \"/content/train/train\"\n",
        "test_path = \"/content/test/test\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# ‚öôÔ∏è STEP 3: IMAGE CONFIG & GENERATORS\n",
        "# ---------------------------------------------\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16  # Reduce for memory-intensive models\n",
        "EPOCHS = 10\n",
        "\n",
        "def get_data_generators(preprocess_input):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_gen = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_gen, test_gen\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üß† STEP 4: BUILD & TRAIN MODEL (WITH TUNING)\n",
        "# ---------------------------------------------\n",
        "def train_with_hyperparams(base_model_class, preprocess_func, dense_units=128, dropout_rate=0.3, learning_rate=1e-4, unfreeze_layers=0):\n",
        "    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    if unfreeze_layers > 0:\n",
        "        base_model.trainable = True\n",
        "        for layer in base_model.layers[:-unfreeze_layers]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(dense_units, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    train_gen, test_gen = get_data_generators(preprocess_func)\n",
        "\n",
        "    history = model.fit(train_gen, epochs=EPOCHS, validation_data=test_gen, verbose=1)\n",
        "    return model, history, test_gen\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üîç STEP 5: EVALUATE AND COMPARE MODELS\n",
        "# ---------------------------------------------\n",
        "def evaluate_model(model_name, base_model_class, preprocess_func, configs):\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "    best_test_gen = None\n",
        "    best_config = None\n",
        "    best_preds = None\n",
        "    best_true_labels = None\n",
        "\n",
        "    for idx, config in enumerate(configs):\n",
        "        print(f\"\\nüîß Training {model_name} - Config {idx+1}: {config}\")\n",
        "        model, history, test_gen = train_with_hyperparams(\n",
        "            base_model_class, preprocess_func,\n",
        "            dense_units=config[\"dense_units\"],\n",
        "            dropout_rate=config[\"dropout_rate\"],\n",
        "            learning_rate=config[\"learning_rate\"],\n",
        "            unfreeze_layers=config[\"unfreeze_layers\"]\n",
        "        )\n",
        "\n",
        "        acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "        if acc > best_accuracy:\n",
        "            best_accuracy = acc\n",
        "            best_model = model\n",
        "            best_test_gen = test_gen\n",
        "            best_config = config\n",
        "            preds = best_model.predict(best_test_gen)\n",
        "            best_preds = np.argmax(preds, axis=1)\n",
        "            best_true_labels = best_test_gen.classes\n",
        "\n",
        "    if best_model:\n",
        "        best_model.save(f\"best_model_{model_name.lower()}.keras\")\n",
        "        print(f\"\\n‚úÖ Best {model_name} model saved with val_accuracy: {best_accuracy:.4f}\")\n",
        "        print(f\"Best config: {best_config}\")\n",
        "\n",
        "        print(f\"\\nüìä {model_name} Classification Report:\")\n",
        "        class_labels = list(best_test_gen.class_indices.keys())\n",
        "        print(classification_report(best_true_labels, best_preds, target_names=class_labels))\n",
        "\n",
        "        cm = confusion_matrix(best_true_labels, best_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_labels, yticklabels=class_labels, cmap=\"Blues\")\n",
        "        plt.title(f\"{model_name} - Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.show()\n",
        "\n",
        "    return model_name, best_accuracy\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üîÅ STEP 6: HYPERPARAMETER CONFIGS\n",
        "# ---------------------------------------------\n",
        "configs = [\n",
        "    {\n",
        "        \"dense_units\": 2048,         # Maximize representational power\n",
        "        \"dropout_rate\": 0.0,         # No regularization ‚Äî let the model fully fit\n",
        "        \"learning_rate\": 1e-3,       # High learning rate for fast adaptation\n",
        "        \"unfreeze_layers\": 100       # Fine-tune as much of the base model as possible\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üöÄ STEP 7: TRAIN & COMPARE ALL MODELS\n",
        "# ---------------------------------------------\n",
        "results = []\n",
        "results.append(evaluate_model(\"ResNet101\", ResNet101, resnet_preprocess, configs))\n",
        "results.append(evaluate_model(\"EfficientNetB7\", EfficientNetB7, efficientnet_preprocess, configs))\n",
        "results.append(evaluate_model(\"DenseNet201\", DenseNet201, densenet_preprocess, configs))\n",
        "\n",
        "# ---------------------------------------------\n",
        "# üìà STEP 8: FINAL COMPARISON TABLE\n",
        "# ---------------------------------------------\n",
        "print(\"\\nüìà Model Comparison Results:\")\n",
        "for name, acc in results:\n",
        "    print(f\"{name}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "JDVbyIzgmlwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìà STEP 8: FINAL COMPARISON TABLE\n",
        "# ---------------------------------------------\n",
        "print(\"\\nüìà Model Comparison Results:\")\n",
        "for name, acc in results:\n",
        "    print(f\"{name}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "I1T0Q0J_CMAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------\n",
        "# üì¶ STEP 1: IMPORT LIBRARIES\n",
        "# ---------------------------------------------\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet101, EfficientNetB7, DenseNet201\n",
        "from keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
        "from keras.applications.densenet import preprocess_input as densenet_preprocess\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "c-zqrizXAIAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# üìÇ STEP 2: EXTRACT DATASETS\n",
        "# ---------------------------------------------\n",
        "train_zip_path = \"/content/test.zip\"\n",
        "test_zip_path = \"/content/test.zip\"\n",
        "\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/train\")\n",
        "\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/test\")\n",
        "\n",
        "train_path = \"/content/train/train\"\n",
        "test_path = \"/content/test/test\"\n"
      ],
      "metadata": {
        "id": "f3HSEEYrAMYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16  # Reduce for memory-intensive models\n",
        "EPOCHS = 5\n",
        "\n",
        "def get_data_generators(preprocess_input):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    test_gen = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_gen, test_gen\n"
      ],
      "metadata": {
        "id": "SIzb0wvXAp-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# üß† STEP 4: BUILD & TRAIN MODEL (WITH TUNING)\n",
        "# ---------------------------------------------\n",
        "def train_with_hyperparams(base_model_class, preprocess_func, dense_units=128, dropout_rate=0.3, learning_rate=1e-4, unfreeze_layers=0):\n",
        "    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    if unfreeze_layers > 0:\n",
        "        base_model.trainable = True\n",
        "        for layer in base_model.layers[:-unfreeze_layers]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(dense_units, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    train_gen, test_gen = get_data_generators(preprocess_func)\n",
        "\n",
        "    history = model.fit(train_gen, epochs=EPOCHS, validation_data=test_gen, verbose=1)\n",
        "    return model, history, test_gen\n",
        "\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "5Cv1cVKnA0Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #üîç STEP 5: EVALUATE AND COMPARE MODELS\n",
        "# ---------------------------------------------\n",
        "def evaluate_model(model_name, base_model_class, preprocess_func, configs):\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "    best_test_gen = None\n",
        "    best_config = None\n",
        "    best_preds = None\n",
        "    best_true_labels = None\n",
        "\n",
        "    for idx, config in enumerate(configs):\n",
        "        print(f\"\\nüîß Training {model_name} - Config {idx+1}: {config}\")\n",
        "        model, history, test_gen = train_with_hyperparams(\n",
        "            base_model_class, preprocess_func,\n",
        "            dense_units=config[\"dense_units\"],\n",
        "            dropout_rate=config[\"dropout_rate\"],\n",
        "            learning_rate=config[\"learning_rate\"],\n",
        "            unfreeze_layers=config[\"unfreeze_layers\"]\n",
        "        )\n",
        "\n",
        "        acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "        if acc > best_accuracy:\n",
        "            best_accuracy = acc\n",
        "            best_model = model\n",
        "            best_test_gen = test_gen\n",
        "            best_config = config\n",
        "            preds = best_model.predict(best_test_gen)\n",
        "            best_preds = np.argmax(preds, axis=1)\n",
        "            best_true_labels = best_test_gen.classes\n",
        "\n",
        "    if best_model:\n",
        "        best_model.save(f\"best_model_{model_name.lower()}.keras\")\n",
        "        print(f\"\\n‚úÖ Best {model_name} model saved with val_accuracy: {best_accuracy:.4f}\")\n",
        "        print(f\"Best config: {best_config}\")\n",
        "\n",
        "        print(f\"\\nüìä {model_name} Classification Report:\")\n",
        "        class_labels = list(best_test_gen.class_indices.keys())\n",
        "        print(classification_report(best_true_labels, best_preds, target_names=class_labels))\n",
        "\n",
        "        cm = confusion_matrix(best_true_labels, best_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_labels, yticklabels=class_labels, cmap=\"Blues\")\n",
        "        plt.title(f\"{model_name} - Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.show()\n",
        "\n",
        "    return model_name, best_accuracy"
      ],
      "metadata": {
        "id": "KKqGOFUFATzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# üîÅ STEP 6: HYPERPARAMETER CONFIGS\n",
        "# ---------------------------------------------\n",
        "configs = [\n",
        "    {\"dense_units\": 128, \"dropout_rate\": 0.3, \"learning_rate\": 1e-4, \"unfreeze_layers\": 0},\n",
        "    {\"dense_units\": 256, \"dropout_rate\": 0.5, \"learning_rate\": 5e-5, \"unfreeze_layers\": 20},\n",
        "    {\"dense_units\": 512, \"dropout_rate\": 0.4, \"learning_rate\": 1e-5, \"unfreeze_layers\": 30},\n",
        "]\n"
      ],
      "metadata": {
        "id": "FJBND6loBMjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# üöÄ STEP 7: TRAIN & COMPARE ALL MODELS\n",
        "# ---------------------------------------------\n",
        "results = []\n",
        "results.append(evaluate_model(\"ResNet101\", ResNet101, resnet_preprocess, configs))\n",
        "results.append(evaluate_model(\"EfficientNetB7\", EfficientNetB7, efficientnet_preprocess, configs))\n",
        "results.append(evaluate_model(\"DenseNet201\", DenseNet201, densenet_preprocess, configs))\n"
      ],
      "metadata": {
        "id": "VD3FN_uIBMm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLXguNho-7sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YynaQbtkm5h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this code we are using hyper parameters tunnung"
      ],
      "metadata": {
        "id": "WZv9pTH6Cw28"
      }
    }
  ]
}